{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f25025ad",
   "metadata": {},
   "source": [
    "Part 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a446b",
   "metadata": {},
   "source": [
    "Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define source dataset directory\n",
    "source_dataset = \"tamil-dataset\" \n",
    "\n",
    "# Create final_data directory\n",
    "base = \"final_data\"\n",
    "\n",
    "train = os.path.join(base, 'train')\n",
    "test = os.path.join(base, 'test')\n",
    "os.makedirs(train)\n",
    "os.makedirs(test)\n",
    "\n",
    "# Get class names from source dataset\n",
    "classes = [d for d in os.listdir(source_dataset) if os.path.isdir(os.path.join(source_dataset, d))]\n",
    "\n",
    "print(f\"Found classes: {classes}\")\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Collect all image paths and labels\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(source_dataset, class_name)\n",
    "    images = os.listdir(class_path)\n",
    "    \n",
    "    # Create class directories in train and test folders\n",
    "    os.makedirs(os.path.join(train, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test, class_name), exist_ok=True)\n",
    "    \n",
    "    for img in images:\n",
    "        if img.lower().endswith(('.tiff')):\n",
    "            all_images.append(os.path.join(class_path, img))\n",
    "            all_labels.append(class_name)\n",
    "\n",
    "print(f\"Total images found: {len(all_images)}\")\n",
    "\n",
    "print(\"Splitting data (80% Train, 20% Test)\")\n",
    "\n",
    "# Stratified split to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_images, \n",
    "    all_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=all_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "def copy_images(image_list, labels, destination_folder):\n",
    "    for src_path, label in zip(image_list, labels):\n",
    "        dst_path = os.path.join(destination_folder, label, os.path.basename(src_path))\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(\"Copying training images\")\n",
    "copy_images(X_train, y_train, train)\n",
    "\n",
    "print(\"Copying test images\")\n",
    "copy_images(X_test, y_test, test)\n",
    "\n",
    "print(\"\\nData Split Summary:\")\n",
    "print(f\"Training Images: {len(X_train)}\")\n",
    "print(f\"Test Images:     {len(X_test)}\")\n",
    "print(f\"Total:           {len(X_train) + len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29355b21",
   "metadata": {},
   "source": [
    "Part 2: Data Preview and Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc530243",
   "metadata": {},
   "source": [
    "Displaying random 3 sample of images from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Dataset path\n",
    "train_dir = \"final_data/train\"\n",
    "classes = os.listdir(train_dir)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "img_count = 1\n",
    "\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    images = random.sample(os.listdir(class_path), 3)\n",
    "    \n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        # Load image using tf.keras.utils.load_img\n",
    "        img = tf.keras.utils.load_img(img_path, color_mode=\"grayscale\")\n",
    "        # Convert to array\n",
    "        img_array = tf.keras.utils.img_to_array(img)\n",
    "        \n",
    "        plt.subplot(len(classes), 3, img_count)\n",
    "        plt.imshow(tf.squeeze(img_array), cmap=\"gray\")\n",
    "        plt.title(class_name)\n",
    "        plt.axis(\"off\")\n",
    "        img_count += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319f20b",
   "metadata": {},
   "source": [
    "Keras Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdee1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*Using \".tiff\" files with multiple bands.*')\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras._tf_keras.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define Generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load Training Data\n",
    "print(\"Loading Training Data:\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load Validation Data\n",
    "print(\"\\nLoading Validation Data:\")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa1742",
   "metadata": {},
   "source": [
    "Part 3: Model Definition, Tuning, and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30cf210",
   "metadata": {},
   "source": [
    "Define two models: a custom Simple CNN and a Transfer Learning Model\n",
    "(MobileNetV2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7f894",
   "metadata": {},
   "source": [
    "Simple CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739da1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_simple_cnn(input_shape=(64,64,1), num_classes=4):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=input_shape),  # <-- input layer\n",
    "        \n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Instantiate\n",
    "simple_cnn = build_simple_cnn()\n",
    "simple_cnn.compile(\n",
    "    optimizer='adam',                 \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'] \n",
    ")\n",
    "simple_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e52cf3",
   "metadata": {},
   "source": [
    "Transfer Learning Model (MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_transfer_model(num_classes=4):\n",
    "    input_tensor = tf.keras.Input(shape=(64, 64, 1)) \n",
    "    \n",
    "    # Resize up to 224x224\n",
    "    x = tf.keras.layers.Resizing(224, 224)(input_tensor)\n",
    "    \n",
    "    # Convert 0-1 range to -1-1 range for MobileNet\n",
    "    x = tf.keras.layers.Rescaling(scale=2.0, offset=-1.0)(x)\n",
    "    \n",
    "    # Convert grayscale to RGB\n",
    "    x = tf.keras.layers.Lambda(lambda x: tf.image.grayscale_to_rgb(x))(x)\n",
    "    \n",
    "    # Load MobileNetV2 Model\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Connect Base Model\n",
    "    x = base_model(x, training=False)\n",
    "    \n",
    "    # Add Classification Head\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)  # Added Dropout for safety\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create Model\n",
    "    model = tf.keras.models.Model(inputs=input_tensor, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Instantiate\n",
    "print(\"Building Transfer Learning Model...\")\n",
    "transfer_model = build_transfer_model(num_classes=4)\n",
    "\n",
    "# Compile\n",
    "transfer_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e2936",
   "metadata": {},
   "source": [
    "HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_hypermodel(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(64, 64, 1)))\n",
    "    \n",
    "    # Tuner decides: 32, 64, or 96 filters?\n",
    "    hp_filters = hp.Int('filters', min_value=32, max_value=96, step=32)\n",
    "    model.add(tf.keras.layers.Conv2D(hp_filters, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    # Tuner decides: 64, 128, or 192 units?\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=256, step=64)\n",
    "    model.add(tf.keras.layers.Dense(hp_units, activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "    \n",
    "    # Tuner decides: Learning rate?\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_log',\n",
    "    project_name='cnn_tuning',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "print(\"Searching for best hyperparameters...\")\n",
    "tuner.search(train_generator, epochs=5, validation_data=validation_generator)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\nSimple CNN Hyperparameters:\")\n",
    "print(f\"{{'learning_rate': {best_hps.get('learning_rate')}, \"\n",
    "      f\"'units': {best_hps.get('units')}, \"\n",
    "      f\"'filters': {best_hps.get('filters')}}}\")\n",
    "\n",
    "# overwrite 'simple_cnn'\n",
    "simple_cnn = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "print(\"\\nSuccess! 'simple_cnn' has been tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09dd16",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cnn_log = tf.keras.callbacks.CSVLogger('model_cnn_training.log')\n",
    "transfer_log = tf.keras.callbacks.CSVLogger('model_transfer_training.log')\n",
    "\n",
    "# Train Simple CNN\n",
    "print(\"Training Simple CNN...\")\n",
    "history_cnn = simple_cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=15,                 # It will try to loop 15 times\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[cnn_log]\n",
    ")\n",
    "# Save it\n",
    "simple_cnn.save('model_cnn.h5')\n",
    "\n",
    "\n",
    "# Train Transfer Learning Model\n",
    "print(\"\\nTraining Transfer Learning Model...\")\n",
    "history_transfer = transfer_model.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[transfer_log]\n",
    ")\n",
    "# Save it\n",
    "transfer_model.save('model_transfer.h5')\n",
    "\n",
    "print(\"\\nDONE! Models are now trained and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba64e8",
   "metadata": {},
   "source": [
    "Part 4: Model Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dca16c",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580239c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"final_data/test\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False \n",
    ")\n",
    "\n",
    "def evaluate_model(model, model_name):\n",
    "    print(f\"\\nEvaluating {model_name}:\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    print(f\"{model_name} Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    test_generator.reset()\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "    \n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "acc_cnn = evaluate_model(simple_cnn, \"Simple CNN\")\n",
    "acc_transfer = evaluate_model(transfer_model, \"Transfer Model\")\n",
    "\n",
    "print(\"\\nFinal Comparison\")\n",
    "print(f\"Simple CNN Accuracy: {acc_cnn*100:.2f}%\")\n",
    "print(f\"Transfer Model Accuracy: {acc_transfer*100:.2f}%\")\n",
    "best_model = transfer_model if acc_transfer > acc_cnn else simple_cnn\n",
    "best_name = \"Transfer Model\" if acc_transfer > acc_cnn else \"Simple CNN\"\n",
    "print(f\"The winner is: {best_name}\")\n",
    "\n",
    "print(f\"\\nVisualizing 10 Samples from {best_name}:\")\n",
    "\n",
    "def visualize_10_samples(model):\n",
    "    temp_gen = test_datagen.flow_from_directory(\n",
    "        \"final_data/test\", target_size=(64, 64), batch_size=32, \n",
    "        color_mode='grayscale', class_mode='categorical', shuffle=True\n",
    "    )\n",
    "    images, labels = next(temp_gen)\n",
    "    \n",
    "    preds = model.predict(images)\n",
    "    pred_classes = np.argmax(preds, axis=1)\n",
    "    true_classes = np.argmax(labels, axis=1)\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "    correct = np.sum(pred_classes[:10] == true_classes[:10])\n",
    "    print(f\"Accuracy over 10 samples: {correct}/10 ({correct*10}%)\")\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i in range(10):\n",
    "        ax = plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        \n",
    "        is_correct = pred_classes[i] == true_classes[i]\n",
    "        color = 'green' if is_correct else 'red'\n",
    "        \n",
    "        plt.title(f\"True: {class_names[true_classes[i]]}\\nPred: {class_names[pred_classes[i]]}\", color=color)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_10_samples(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a858192",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121894ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nImage Provided Result:\")\n",
    "\n",
    "def predict_user_image(model, img_path):\n",
    "    try:\n",
    "        img = tf.keras.utils.load_img(img_path, target_size=(64, 64), color_mode='grayscale')\n",
    "        \n",
    "        img_array = tf.keras.utils.img_to_array(img)\n",
    "        img_array = img_array / 255.0\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        prediction = model.predict(img_batch)\n",
    "        class_idx = np.argmax(prediction)\n",
    "        \n",
    "        class_labels = list(test_generator.class_indices.keys())\n",
    "        predicted_label = class_labels[class_idx]\n",
    "        confidence = prediction[0][class_idx]\n",
    "        \n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(img_array.squeeze(), cmap='gray')\n",
    "        plt.title(f\"Pred: {predicted_label} ({confidence*100:.1f}%)\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not read image at {img_path}. Check the path.\")\n",
    "\n",
    "img_path = input(\"Enter full path to an image to test\")\n",
    "if img_path:\n",
    "    predict_user_image(best_model, img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
